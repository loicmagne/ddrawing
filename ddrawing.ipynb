{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies - Restart runtime after executing next cell\n"
      ],
      "metadata": {
        "id": "P3oRn6W0SjV8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDVJ80xeQVMf",
        "outputId": "805f9ada-0895-490a-ce25-9e706c20e641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.1-py3-none-any.whl (66 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 20 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 30 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 40 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 51 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 61 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 66 kB 1.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: svgwrite\n",
            "Successfully installed svgwrite-1.4.1\n",
            "Collecting svgpathtools\n",
            "  Downloading svgpathtools-1.4.4-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: svgwrite in /usr/local/lib/python3.7/dist-packages (from svgpathtools) (1.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from svgpathtools) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from svgpathtools) (1.19.5)\n",
            "Installing collected packages: svgpathtools\n",
            "Successfully installed svgpathtools-1.4.4\n",
            "Collecting cssutils\n",
            "  Downloading cssutils-2.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[K     |████████████████████████████████| 404 kB 14.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from cssutils) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->cssutils) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->cssutils) (3.10.0.2)\n",
            "Installing collected packages: cssutils\n",
            "Successfully installed cssutils-2.3.0\n",
            "Collecting lpips\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.4.1)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.7/dist-packages (from lpips) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from lpips) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->lpips) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.1->lpips) (7.1.2)\n",
            "Installing collected packages: lpips\n",
            "Successfully installed lpips-0.1.4\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=e433eea2082692ed67beb6f1f0aa6c614dd8f90c65d2fb3462b68d9e08ba4c60\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 14.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=1a4a52a46c1cdb935375959504670f0c352635f7659b609465a1eda899350233\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3523023f7b9bb62f254bb88c6f9f1e3bf4849c2923bd354551c41f136d256b00\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
            "Successfully installed GitPython-3.1.26 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.2 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.9 yaspin-2.1.0\n",
            "Cloning into 'diffvg'...\n",
            "remote: Enumerating objects: 279, done.\u001b[K\n",
            "remote: Total 279 (delta 0), reused 0 (delta 0), pack-reused 279\u001b[K\n",
            "Receiving objects: 100% (279/279), 10.27 MiB | 25.77 MiB/s, done.\n",
            "Resolving deltas: 100% (105/105), done.\n",
            "/content/diffvg\n",
            "Submodule 'pybind11' (https://github.com/pybind/pybind11.git) registered for path 'pybind11'\n",
            "Submodule 'thrust' (https://github.com/thrust/thrust.git) registered for path 'thrust'\n",
            "Cloning into '/content/diffvg/pybind11'...\n",
            "Cloning into '/content/diffvg/thrust'...\n",
            "Submodule path 'pybind11': checked out '72b06b86b3824781f31c790dfce67e26e6307816'\n",
            "Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3.git) registered for path 'pybind11/tools/clang'\n",
            "Cloning into '/content/diffvg/pybind11/tools/clang'...\n",
            "Submodule path 'pybind11/tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5'\n",
            "Submodule path 'thrust': checked out 'ff00c813aa3a6bbfd1d8c338313f382b6b340005'\n",
            "Submodule 'cub' (https://github.com/thrust/cub.git) registered for path 'thrust/dependencies/cub'\n",
            "Cloning into '/content/diffvg/thrust/dependencies/cub'...\n",
            "Submodule path 'thrust/dependencies/cub': checked out '2442f44532ffcc53298c7e3a298feb5134563860'\n",
            "WARNING:tensorflow:From setup.py:82: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "2022-01-14 21:13:21.754613: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating diffvg.egg-info\n",
            "writing diffvg.egg-info/PKG-INFO\n",
            "writing dependency_links to diffvg.egg-info/dependency_links.txt\n",
            "writing requirements to diffvg.egg-info/requires.txt\n",
            "writing top-level names to diffvg.egg-info/top_level.txt\n",
            "writing manifest file 'diffvg.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'diffvg.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/color.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/render_pytorch.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/parse_svg.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/image.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/save_svg.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/__init__.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/shape.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/device.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/optimize_svg.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "copying pydiffvg/pixel_filter.py -> build/lib.linux-x86_64-3.7/pydiffvg\n",
            "creating build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/color.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/image.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/__init__.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/render_tensorflow.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/shape.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/device.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "copying pydiffvg_tensorflow/pixel_filter.py -> build/lib.linux-x86_64-3.7/pydiffvg_tensorflow\n",
            "running build_ext\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Python: /usr/lib/python3.7/config-3.7m-x86_64-linux-gnu/libpython3.7m.so (found suitable version \"3.7.12\", minimum required is \"3.7\") found components:  Development \n",
            "-- pybind11 v2.6.0 dev\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Using pybind11: (version \"2.6.0\" dev)\n",
            "-- Build without CUDA support\n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.7m.so (found version \"3.7.12\") \n",
            "INFO Building without TensorFlow support (not found)\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/diffvg/build/temp.linux-x86_64-3.7\n",
            "\u001b[35m\u001b[1mScanning dependencies of target diffvg\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/atomic.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/color.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/parallel.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/diffvg.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/scene.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/diffvg.dir/shape.cpp.o\u001b[0m\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/config.h:27:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/cuda/include/thrust/execution_policy.h:23\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/content/diffvg/diffvg.cpp:22\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/thrust/detail/config/cpp_dialect.h:104:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[KThrust requires C++14. Please pass -std=c++14 to your compiler. Define THRUST_IGNORE_DEPRECATED_CPP_DIALECT to suppress this message.\n",
            "   THRUST_COM\u001b[01;35m\u001b[KPILER_DEPRECATION(C++14, pass -std=c++14 to your compiler);\u001b[m\u001b[K\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K                                                                            \n",
            "/content/diffvg/scene.cpp: In instantiation of ‘\u001b[01m\u001b[Ksize_t allocate_buffers(Scene&, const std::vector<const Shape*>&, const std::vector<const ShapeGroup*>&) [with bool alloc_mode = true; size_t = long unsigned int]\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K/content/diffvg/scene.cpp:964:78:\u001b[m\u001b[K   required from here\n",
            "\u001b[01m\u001b[K/content/diffvg/scene.cpp:732:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "         for (int i = 0; \u001b[01;35m\u001b[Ki < num_shapes\u001b[m\u001b[K; i++) {\n",
            "                         \u001b[01;35m\u001b[K~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module ../lib.linux-x86_64-3.7/diffvg.so\u001b[0m\n",
            "[100%] Built target diffvg\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-3.7/diffvg.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/color.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/render_pytorch.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/parse_svg.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/image.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/save_svg.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/__init__.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/shape.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/device.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/optimize_svg.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg/pixel_filter.py -> build/bdist.linux-x86_64/egg/pydiffvg\n",
            "creating build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/color.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/image.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/__init__.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/render_tensorflow.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/shape.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/device.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "copying build/lib.linux-x86_64-3.7/pydiffvg_tensorflow/pixel_filter.py -> build/bdist.linux-x86_64/egg/pydiffvg_tensorflow\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/color.py to color.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/render_pytorch.py to render_pytorch.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/parse_svg.py to parse_svg.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/image.py to image.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/save_svg.py to save_svg.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/shape.py to shape.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/device.py to device.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/optimize_svg.py to optimize_svg.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg/pixel_filter.py to pixel_filter.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/color.py to color.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/image.py to image.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/render_tensorflow.py to render_tensorflow.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/shape.py to shape.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/device.py to device.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pydiffvg_tensorflow/pixel_filter.py to pixel_filter.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying diffvg.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/diffvg-0.0.1-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing diffvg-0.0.1-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/diffvg-0.0.1-py3.7-linux-x86_64.egg\n",
            "Extracting diffvg-0.0.1-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding diffvg 0.0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/diffvg-0.0.1-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for diffvg==0.0.1\n",
            "Searching for svgpathtools==1.4.4\n",
            "Best match: svgpathtools 1.4.4\n",
            "Adding svgpathtools 1.4.4 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for svgwrite==1.4.1\n",
            "Best match: svgwrite 1.4.1\n",
            "Adding svgwrite 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for diffvg==0.0.1\n",
            "/content\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-de34pv2o\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-de34pv2o\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.62.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.11.1+cu111)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369108 sha256=aa08b6575bb1218a82de03fc9a695d6d532c4953fc83817f28d7d9864fe9839a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8rpky7od/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install svgwrite\n",
        "!pip install svgpathtools\n",
        "!pip install cssutils\n",
        "!pip install lpips\n",
        "!pip install ftfy regex tqdm\n",
        "!pip install wandb\n",
        "\n",
        "# install diffvg\n",
        "!git clone https://github.com/BachiLi/diffvg\n",
        "%cd diffvg\n",
        "!git submodule update --init --recursive\n",
        "!python setup.py install\n",
        "%cd ..\n",
        "\n",
        "# install CLIP\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydiffvg\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import random\n",
        "import lpips\n",
        "import clip\n",
        "import wandb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from subprocess import call\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jFmJXNMES55i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Differentiable Drawing Wrapper"
      ],
      "metadata": {
        "id": "QRl30t_qSoVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DifferentiableDrawer():\n",
        "    def __init__(self, device, width, height, max_stroke_width=2., gamma=1.0, optim=torch.optim.Adam):\n",
        "        pydiffvg.set_print_timing(False)\n",
        "        pydiffvg.set_use_gpu(torch.cuda.is_available())\n",
        "        pydiffvg.set_device(device)\n",
        "        self.device = device\n",
        "        self.canvas_width, self.canvas_height = width, height\n",
        "        self.max_stroke_width, self.gamma = max_stroke_width, gamma\n",
        "        self.shapes = []\n",
        "        self.shape_groups = []\n",
        "        self.points_optim = optim([torch.tensor(0)], lr=1.)\n",
        "        self.color_optim = optim([torch.tensor(0)], lr=0.05)\n",
        "        self.width_optim = optim([torch.tensor(0)], lr=0.01)\n",
        "        self.renderer = pydiffvg.RenderFunction.apply\n",
        "\n",
        "    def add_shapes(self, n=256, shape=\"path\", pts_range=(1,4)):\n",
        "        \"\"\"\n",
        "        Add shapes to the set of shapes\n",
        "        The shape parameter should be :\n",
        "        - path\n",
        "        - filled_path \n",
        "        \"\"\"\n",
        "        # Define shapes\n",
        "        shapes = []\n",
        "        shape_groups = []\n",
        "        if shape==\"filled_path\":\n",
        "            for i in range(n):\n",
        "                num_segments = random.randint(pts_range[0], pts_range[1])\n",
        "                num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
        "                points = []\n",
        "                p0 = (random.random(), random.random())\n",
        "                points.append(p0)\n",
        "                for j in range(num_segments):\n",
        "                    radius = 0.05\n",
        "                    p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
        "                    p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
        "                    p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
        "                    points.append(p1)\n",
        "                    points.append(p2)\n",
        "                    if j < num_segments - 1:\n",
        "                        points.append(p3)\n",
        "                        p0 = p3\n",
        "                points = torch.tensor(points)\n",
        "                points[:, 0] *= canvas_width\n",
        "                points[:, 1] *= canvas_height\n",
        "                path = pydiffvg.Path(\n",
        "                    num_control_points = num_control_points,\n",
        "                    points = points,\n",
        "                    stroke_width = torch.tensor(1.0),\n",
        "                    is_closed = True\n",
        "                )\n",
        "                shapes.append(path)\n",
        "                path_group = pydiffvg.ShapeGroup(\n",
        "                    shape_ids = torch.tensor([len(shapes) - 1]),\n",
        "                    fill_color = torch.tensor([\n",
        "                        random.random(),\n",
        "                        random.random(),\n",
        "                        random.random(),\n",
        "                        random.random()\n",
        "                    ])\n",
        "                )\n",
        "                shape_groups.append(path_group)\n",
        "        elif shape==\"path\":\n",
        "            for i in range(n):\n",
        "                num_segments = random.randint(pts_range[0], pts_range[1])\n",
        "                num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
        "                points = []\n",
        "                p0 = (random.random(), random.random())\n",
        "                points.append(p0)\n",
        "                for j in range(num_segments):\n",
        "                    radius = 0.05\n",
        "                    p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
        "                    p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
        "                    p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
        "                    points.append(p1)\n",
        "                    points.append(p2)\n",
        "                    points.append(p3)\n",
        "                    p0 = p3\n",
        "                points = torch.tensor(points)\n",
        "                points[:, 0] *= canvas_width\n",
        "                points[:, 1] *= canvas_height\n",
        "                #points = torch.rand(3 * num_segments + 1, 2) * min(canvas_width, canvas_height)\n",
        "                path = pydiffvg.Path(\n",
        "                    num_control_points = num_control_points,\n",
        "                    points = points,\n",
        "                    stroke_width = torch.tensor(1.0),\n",
        "                    is_closed = False\n",
        "                )\n",
        "                shapes.append(path)\n",
        "                path_group = pydiffvg.ShapeGroup(\n",
        "                    shape_ids = torch.tensor([len(shapes) - 1]),\n",
        "                    fill_color = None,\n",
        "                    stroke_color = torch.tensor([\n",
        "                        random.random(),\n",
        "                        random.random(),\n",
        "                        random.random(),\n",
        "                        random.random()\n",
        "                    ])\n",
        "                )\n",
        "                shape_groups.append(path_group)\n",
        "        # Get parameters\n",
        "        points_vars = []\n",
        "        color_vars = []\n",
        "        stroke_width_vars = []\n",
        "        for path in shapes:\n",
        "            path.points.requires_grad = True\n",
        "            points_vars.append(path.points)\n",
        "        if shape==\"path\":\n",
        "            for path in shapes:\n",
        "                path.stroke_width.requires_grad = True\n",
        "                stroke_width_vars.append(path.stroke_width)\n",
        "        if shape==\"filled_path\":\n",
        "            for group in shape_groups:\n",
        "                group.fill_color.requires_grad = True\n",
        "                color_vars.append(group.fill_color)\n",
        "        else:\n",
        "            for group in shape_groups:\n",
        "                group.stroke_color.requires_grad = True\n",
        "                color_vars.append(group.stroke_color)\n",
        "        \n",
        "        # Add parameters to optimizer\n",
        "        points_new_optim = torch.optim.Adam(points_vars, lr=1.0)\n",
        "        color_new_optim = torch.optim.Adam(color_vars, lr=0.05)\n",
        "        width_new_optim = torch.optim.Adam(stroke_width_vars, lr=0.01)\n",
        "        self.points_optim.param_groups += points_new_optim.param_groups\n",
        "        self.color_optim.param_groups += color_new_optim.param_groups\n",
        "        self.width_optim.param_groups += width_new_optim.param_groups\n",
        "\n",
        "        self.shapes += shapes\n",
        "        self.shape_groups += shape_groups\n",
        "        \n",
        "    def zero_grad(self):\n",
        "        self.points_optim.zero_grad()\n",
        "        self.color_optim.zero_grad()\n",
        "        self.width_optim.zero_grad()\n",
        "\n",
        "    def step(self):\n",
        "        self.points_optim.step()\n",
        "        self.color_optim.step()\n",
        "        self.width_optim.step()\n",
        "        try:\n",
        "            for group in self.shape_groups:\n",
        "                group.fill_color.data.clamp_(0.0, 1.0)\n",
        "        except AttributeError:\n",
        "            for path in self.shapes:\n",
        "                path.stroke_width.data.clamp_(1.0, max_stroke_width)\n",
        "            for group in self.shape_groups:\n",
        "                group.stroke_color.data.clamp_(0.0, 1.0)\n",
        "\n",
        "\n",
        "    def render(self, seed):\n",
        "        # Forward pass: render the image.\n",
        "        scene_args = pydiffvg.RenderFunction.serialize_scene(\n",
        "            self.canvas_width,\n",
        "            self.canvas_height,\n",
        "            self.shapes,\n",
        "            self.shape_groups\n",
        "        )\n",
        "        img = self.renderer(\n",
        "            self.canvas_width, # width\n",
        "            self.canvas_height, # height\n",
        "            2,   # num_samples_x\n",
        "            2,   # num_samples_y\n",
        "            seed,   # seed\n",
        "            None,\n",
        "            *scene_args\n",
        "        )\n",
        "        # Compose img with white background\n",
        "        img = img[:, :, 3:4] * img[:, :, :3] + torch.ones(img.shape[0], img.shape[1], 3, device = self.device) * (1 - img[:, :, 3:4])\n",
        "        # Save the intermediate render.\n",
        "        pydiffvg.imwrite(img.cpu(), 'results/painterly_rendering/iter_{}.png'.format(t), gamma=self.gamma)\n",
        "        img = img[:, :, :3]\n",
        "        # Convert img from HWC to NCHW\n",
        "        img = img.unsqueeze(0)\n",
        "        img = img.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
        "        return img"
      ],
      "metadata": {
        "id": "QPSfVHpkSs6v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Optimization"
      ],
      "metadata": {
        "id": "PRdqWODxbhg3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "JvqHg46_x8Wi",
        "outputId": "8b8955d0-cbe2-4e51-9012-9bc8bd19f65c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
            "Loading model from: /usr/local/lib/python3.7/dist-packages/lpips/weights/v0.1/vgg.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Finishing last run (ID:eilzzb74) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Successfully finished last run (ID:eilzzb74). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/lmagne/recvis-project/runs/3sxisyqm\" target=\"_blank\">L2_Adam[+100paths/100iter]</a></strong> to <a href=\"https://wandb.ai/lmagne/recvis-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 126/500 [09:06<43:50,  7.03s/it, render_loss=0.0226]"
          ]
        }
      ],
      "source": [
        "import pydiffvg\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import random\n",
        "import lpips\n",
        "import clip\n",
        "import wandb\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from subprocess import call\n",
        "\n",
        "# Parameters\n",
        "n_paths = 100\n",
        "n_iter = 500\n",
        "max_stroke_width = 3\n",
        "gamma = 1.0\n",
        "percep_loss = False # Set True to compare image features instead of L2 loss\n",
        "use_filled_path = False # Set True to use filled curves instead of simple path\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize target image\n",
        "target_img = np.array(Image.open(\"img1.png\").convert('RGB').resize((320,180))) \n",
        "target = torch.from_numpy(target_img).to(torch.float32) / 255.0\n",
        "target = target.pow(gamma)\n",
        "target = target.to(device)\n",
        "target = target.unsqueeze(0)\n",
        "target = target.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
        "canvas_width, canvas_height = target.shape[3], target.shape[2]\n",
        "\n",
        "# Initialize diffvg and drawer\n",
        "drawer = DifferentiableDrawer(\n",
        "    device, \n",
        "    width=canvas_width, \n",
        "    height=canvas_height, \n",
        "    max_stroke_width=max_stroke_width, \n",
        "    gamma=gamma, \n",
        "    optim=torch.optim.Adam\n",
        ")\n",
        "\n",
        "# Add paths\n",
        "drawer.add_shapes(n_paths, shape=\"path\", pts_range=(2,5))\n",
        "\n",
        "l2_criterion = torch.nn.MSELoss()\n",
        "percep_criterion = lpips.LPIPS(net='vgg')\n",
        "\n",
        "NAME = \"L2_Adam[+100paths/100iter]\"\n",
        "wandb.init(\n",
        "    project=\"recvis-project\",\n",
        "    name=NAME\n",
        ")\n",
        "\n",
        "with tqdm(range(n_iter)) as loop:\n",
        "    for t in loop:\n",
        "        # Every 100 iterations, add some paths\n",
        "        if t and (t%100==0):\n",
        "            drawer.add_shapes(n_paths, shape=\"path\", pts_range=(2,5))\n",
        "\n",
        "        metrics = {\n",
        "            'lpips': None,\n",
        "            'L2': None,\n",
        "            'loss': None\n",
        "        }\n",
        "\n",
        "        drawer.zero_grad() # Zero grad\n",
        "        img = drawer.render(t) # Forward pass: render the image.\n",
        "\n",
        "        # Compute losses\n",
        "        l2_loss = l2_criterion(img, target)\n",
        "        lpips_loss = percep_criterion(img,target)\n",
        "        loss = l2_loss\n",
        "\n",
        "        loss.backward() # Backpropagate the gradients.\n",
        "        drawer.step() # Take a gradient descent step.\n",
        "\n",
        "        # Record metrics\n",
        "        with torch.no_grad():\n",
        "            metrics['lpips'] = lpips_loss.item()\n",
        "            metrics['L2'] = l2_loss.item()\n",
        "            metrics['loss'] = loss.item()\n",
        "        loop.set_postfix(render_loss=loss.item())\n",
        "        wandb.log(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIP-Guided Generation"
      ],
      "metadata": {
        "id": "2LOyfn5NbnCq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "R5WNy3CTWn8b",
        "outputId": "85808904-29f5-476c-e251-1fce2a5346c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|███████▍  | 740/1000 [2:01:41<42:45,  9.87s/it, render_loss=-1.51]  \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-62aa71953464>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0mscene_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         )\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Compose img with white background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/diffvg-0.0.1-py3.7-linux-x86_64.egg/pydiffvg/render_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, width, height, num_samples_x, num_samples_y, seed, background_image, *args)\u001b[0m\n\u001b[1;32m    409\u001b[0m                       \u001b[0muse_prefiltering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                       \u001b[0mdiffvg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_positions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                       eval_positions.shape[0])\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendered_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pydiffvg\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import numpy as np\n",
        "import random\n",
        "import clip\n",
        "from google.colab import files\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from subprocess import call\n",
        "\n",
        "# Parameters\n",
        "n_paths = 256\n",
        "n_iter = 1000\n",
        "max_stroke_width = 20\n",
        "gamma = 1.0\n",
        "use_filled_path = False # Set True to use filled curves instead of simple path\n",
        "n_augment = 4 # Number of augmentation per round\n",
        "\n",
        "# Initialize diffvg and GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "pydiffvg.set_print_timing(False)\n",
        "pydiffvg.set_use_gpu(torch.cuda.is_available())\n",
        "pydiffvg.set_device(device)\n",
        "\n",
        "# Load CLIP and target\n",
        "model, preprocess = clip.load('ViT-B/32', device, jit=False)\n",
        "model.eval()\n",
        "target_txt = clip.tokenize(\"Gouache painting of a house in the middle of a field on a sunny day\").to(device)\n",
        "with torch.no_grad():\n",
        "    target_features = model.encode_text(target_txt)\n",
        "canvas_width, canvas_height = 224, 224\n",
        "clip_transforms = transforms.Compose([\n",
        "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), \n",
        "                         (0.26862954, 0.26130258, 0.27577711))\n",
        "])\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.RandomPerspective(fill=1, p=1, distortion_scale=0.5),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.7,0.9)),\n",
        "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), \n",
        "                         (0.26862954, 0.26130258, 0.27577711))\n",
        "])\n",
        "\n",
        "# Initialize Shapes\n",
        "shapes = []\n",
        "shape_groups = []\n",
        "\n",
        "if use_filled_path:\n",
        "    for i in range(n_paths):\n",
        "        num_segments = random.randint(3, 5)\n",
        "        num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
        "        points = []\n",
        "        p0 = (random.random(), random.random())\n",
        "        points.append(p0)\n",
        "        for j in range(num_segments):\n",
        "            radius = 0.05\n",
        "            p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
        "            p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
        "            p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
        "            points.append(p1)\n",
        "            points.append(p2)\n",
        "            if j < num_segments - 1:\n",
        "                points.append(p3)\n",
        "                p0 = p3\n",
        "        points = torch.tensor(points)\n",
        "        points[:, 0] *= canvas_width\n",
        "        points[:, 1] *= canvas_height\n",
        "        path = pydiffvg.Path(\n",
        "            num_control_points = num_control_points,\n",
        "            points = points,\n",
        "            stroke_width = torch.tensor(1.0),\n",
        "            is_closed = True\n",
        "        )\n",
        "        shapes.append(path)\n",
        "        path_group = pydiffvg.ShapeGroup(\n",
        "            shape_ids = torch.tensor([len(shapes) - 1]),\n",
        "            fill_color = torch.tensor([\n",
        "                random.random(),\n",
        "                random.random(),\n",
        "                random.random(),\n",
        "                random.random()\n",
        "            ])\n",
        "        )\n",
        "        shape_groups.append(path_group)\n",
        "else:\n",
        "    for i in range(n_paths):\n",
        "        num_segments = random.randint(1, 2)\n",
        "        num_control_points = torch.zeros(num_segments, dtype = torch.int32) + 2\n",
        "        points = []\n",
        "        p0 = (random.random(), random.random())\n",
        "        points.append(p0)\n",
        "        for j in range(num_segments):\n",
        "            radius = 0.05\n",
        "            p1 = (p0[0] + radius * (random.random() - 0.5), p0[1] + radius * (random.random() - 0.5))\n",
        "            p2 = (p1[0] + radius * (random.random() - 0.5), p1[1] + radius * (random.random() - 0.5))\n",
        "            p3 = (p2[0] + radius * (random.random() - 0.5), p2[1] + radius * (random.random() - 0.5))\n",
        "            points.append(p1)\n",
        "            points.append(p2)\n",
        "            points.append(p3)\n",
        "            p0 = p3\n",
        "        points = torch.tensor(points)\n",
        "        points[:, 0] *= canvas_width\n",
        "        points[:, 1] *= canvas_height\n",
        "        #points = torch.rand(3 * num_segments + 1, 2) * min(canvas_width, canvas_height)\n",
        "        path = pydiffvg.Path(\n",
        "            num_control_points = num_control_points,\n",
        "            points = points,\n",
        "            stroke_width = torch.tensor(1.0),\n",
        "            is_closed = False\n",
        "        )\n",
        "        shapes.append(path)\n",
        "        path_group = pydiffvg.ShapeGroup(\n",
        "            shape_ids = torch.tensor([len(shapes) - 1]),\n",
        "            fill_color = None,\n",
        "            stroke_color = torch.tensor([\n",
        "                random.random(),\n",
        "                random.random(),\n",
        "                random.random(),\n",
        "                random.random()\n",
        "            ])\n",
        "        )\n",
        "        shape_groups.append(path_group)\n",
        "\n",
        "# diffvg setup\n",
        "scene_args = pydiffvg.RenderFunction.serialize_scene(\n",
        "    canvas_width, \n",
        "    canvas_height, \n",
        "    shapes, \n",
        "    shape_groups\n",
        ")\n",
        "render = pydiffvg.RenderFunction.apply\n",
        "img = render(\n",
        "    canvas_width, # width\n",
        "    canvas_height, # height\n",
        "    2,   # num_samples_x\n",
        "    2,   # num_samples_y\n",
        "    0,   # seed\n",
        "    None,\n",
        "    *scene_args\n",
        ")\n",
        "points_vars = []\n",
        "color_vars = []\n",
        "stroke_width_vars = []\n",
        "for path in shapes:\n",
        "    path.points.requires_grad = True\n",
        "    points_vars.append(path.points)\n",
        "if not use_filled_path:\n",
        "    for path in shapes:\n",
        "        path.stroke_width.requires_grad = True\n",
        "        stroke_width_vars.append(path.stroke_width)\n",
        "if use_filled_path:\n",
        "    for group in shape_groups:\n",
        "        group.fill_color.requires_grad = True\n",
        "        color_vars.append(group.fill_color)\n",
        "else:\n",
        "    for group in shape_groups:\n",
        "        group.stroke_color.requires_grad = True\n",
        "        color_vars.append(group.stroke_color)\n",
        "\n",
        "def shift_image(x=0.8):\n",
        "    with torch.no_grad():\n",
        "        for path in shapes:\n",
        "            path.points *= x\n",
        "\n",
        "# Optimizers and losses\n",
        "points_optim = torch.optim.Adam(points_vars, lr=2.0)\n",
        "color_optim = torch.optim.Adam(color_vars, lr=0.01)\n",
        "width_optim = torch.optim.Adam(stroke_width_vars, lr=0.01)\n",
        "\n",
        "with tqdm(range(n_iter)) as loop:\n",
        "    for t in loop:\n",
        "        # Zero grad\n",
        "        points_optim.zero_grad()\n",
        "        color_optim.zero_grad()\n",
        "        width_optim.zero_grad()\n",
        "\n",
        "        # Forward pass: render the image.\n",
        "        scene_args = pydiffvg.RenderFunction.serialize_scene(\n",
        "            canvas_width,\n",
        "            canvas_height,\n",
        "            shapes,\n",
        "            shape_groups\n",
        "        )\n",
        "        img = render(\n",
        "            canvas_width, # width\n",
        "            canvas_height, # height\n",
        "            2,   # num_samples_x\n",
        "            2,   # num_samples_y\n",
        "            t,   # seed\n",
        "            None,\n",
        "            *scene_args\n",
        "        )\n",
        "        # Compose img with white background\n",
        "        img = img[:, :, 3:4] * img[:, :, :3] + torch.ones(img.shape[0], img.shape[1], 3, device = device) * (1 - img[:, :, 3:4])\n",
        "        # Save the intermediate render.\n",
        "        pydiffvg.imwrite(img.cpu(), 'results/painterly_rendering/iter_{}.png'.format(t), gamma=gamma)\n",
        "        img = img[:, :, :3]\n",
        "        # Convert img from HWC to NCHW\n",
        "        img = img.unsqueeze(0)\n",
        "        img = img.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
        "\n",
        "        loss = 0\n",
        "        imgs = torch.cat([augmentation_transforms(img) for i in range(n_augment)])\n",
        "        imgs_features = model.encode_image(imgs)\n",
        "        for i in range(n_augment):\n",
        "            loss -= torch.cosine_similarity(target_features, imgs_features[i:i+1], dim=1)\n",
        "            \n",
        "        # loss = torch.cosine_similarity(target_features, model.encode_image(clip_transforms(img)), dim=1)\n",
        "        # Backpropagate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Take a gradient descent step.\n",
        "        points_optim.step()\n",
        "        color_optim.step()\n",
        "        width_optim.step()\n",
        "        if use_filled_path:\n",
        "            for group in shape_groups:\n",
        "                group.fill_color.data.clamp_(0.0, 1.0)\n",
        "        else:\n",
        "            for path in shapes:\n",
        "                path.stroke_width.data.clamp_(1.0, max_stroke_width)\n",
        "            for group in shape_groups:\n",
        "                group.stroke_color.data.clamp_(0.0, 1.0)\n",
        "\n",
        "        # log\n",
        "        loop.set_postfix(render_loss=loss.item())\n",
        "\n",
        "\n",
        "call([\"ffmpeg\", \"-framerate\", \"60\", \"-i\",\n",
        "    \"results/painterly_rendering/iter_%d.png\", \"-vb\", \"20M\",\n",
        "    \"results/painterly_rendering/out.mp4\"])\n",
        "files.download('results/painterly_rendering/out.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "id": "Nf1vwLhJwgN3",
        "outputId": "cc7cf9b1-799e-4fdb-a7ea-e4c420d26e84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from 'results/painterly_rendering/iter_%d.png':\n",
            "  Duration: 00:00:08.33, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 320x180, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mprofile High 4:4:4 Predictive, level 3.2, 4:4:4 8-bit\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x1:0x111 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=0 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=40000 ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to 'results/painterly_rendering/out.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv444p, 320x180, q=-1--1, 40000 kb/s, 60 fps, 15360 tbn, 60 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/40000000 buffer size: 0 vbv_delay: -1\n",
            "frame=  500 fps= 47 q=-1.0 Lsize=   29849kB time=00:00:08.28 bitrate=29519.6kbits/s speed=0.786x    \n",
            "video:29842kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.022665%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mframe I:2     Avg QP: 0.41  size: 73080\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mframe P:133   Avg QP: 0.14  size: 73694\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mframe B:365   Avg QP: 3.31  size: 56467\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mconsecutive B-frames:  2.6%  0.0%  0.6% 96.8%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mmb I  I16..4:  4.8%  0.0% 95.2%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mmb P  I16..4:  0.8%  0.0%  2.4%  P16..4: 21.5% 34.9% 39.9%  0.0%  0.0%    skip: 0.5%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.8%  B16..8: 16.3% 12.2% 40.6%  direct:29.3%  skip: 0.7%  L0:37.3% L1:27.0% BI:35.7%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mfinal ratefactor: -11.10\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mcoded y,u,v intra: 53.5% 52.1% 53.4% inter: 93.3% 88.6% 90.2%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mi16 v,h,dc,p: 66% 20% 14%  0%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 47% 18% 15%  3%  3%  2%  5%  2%  5%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mWeighted P-Frames: Y:16.5% UV:2.3%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mref P L0: 39.4% 14.8% 27.3% 17.9%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mref B L0: 68.2% 24.9%  6.9%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mref B L1: 85.3% 14.7%\n",
            "\u001b[1;36m[libx264 @ 0x560d5ebf1e00] \u001b[0mkb/s:29335.41\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f2b1ec4d-e147-44f6-b3c9-3a59c581120d\", \"out.mp4\", 30565351)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "!ffmpeg -y -framerate 60 -i results/painterly_rendering/iter_%d.png -vb 40M results/painterly_rendering/out.mp4\n",
        "files.download('results/painterly_rendering/out.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V3dPc94IWiS1"
      },
      "outputs": [],
      "source": [
        "!rm -r results/painterly_rendering/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcEFxiGRXsPn",
        "outputId": "80e21ee7-2dea-4f56-d0b4-c42d718ecf48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKtG9dR-F5Tn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "recvis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}